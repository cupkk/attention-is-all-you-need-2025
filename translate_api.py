import sys
import os
import time
import logging

# æ·»åŠ å½“å‰ç›®å½•åˆ° Python è·¯å¾„
current_dir = os.path.dirname(os.path.abspath(__file__))
if current_dir not in sys.path:
    sys.path.append(current_dir)

# å¯¼å…¥æ¨¡å—
from utils.mask import generate_square_subsequent_mask

import torch
import torch.nn as nn
import torch.nn.functional as F
import matplotlib.pyplot as plt
import seaborn as sns
import numpy as np
import shutil
from jinja2 import Template
import sentencepiece as spm  # BPE åˆ†è¯æ”¯æŒ

# BPE åˆ†è¯å™¨å…¨å±€å˜é‡ï¼ˆå»¶è¿ŸåŠ è½½ï¼‰
sp_de = None
sp_en = None

# è¯è¡¨åå‘æ˜ å°„å…¨å±€å˜é‡
idx_to_token_src = None
idx_to_token_tgt = None

def _load_bpe_models():
    """å»¶è¿ŸåŠ è½½ BPE åˆ†è¯å™¨"""
    global sp_de, sp_en
    if sp_de is None or sp_en is None:
        # è·å–é¡¹ç›®æ ¹ç›®å½•çš„ç»å¯¹è·¯å¾„
        script_dir = os.path.dirname(os.path.abspath(__file__))
        bpe_dir = os.path.join(script_dir, "bpe_models")
        
        sp_de = spm.SentencePieceProcessor()
        sp_de.Load(os.path.join(bpe_dir, "bpe_de.model"))
        
        sp_en = spm.SentencePieceProcessor()
        sp_en.Load(os.path.join(bpe_dir, "bpe_en.model"))

# ä½¿ç”¨ BPE åˆ†è¯å‡½æ•°
def tokenize_de(text):
    _load_bpe_models()
    return sp_de.encode_as_pieces(text.strip())

def tokenize_en(text):
    _load_bpe_models()
    return sp_en.encode_as_pieces(text.strip())

# ç‰¹æ®Šç¬¦å·ç´¢å¼•
PAD_IDX = 1
BOS_IDX = 2
EOS_IDX = 3

def plot_attention_weights(src_tokens, tgt_tokens, attention_matrix, filename="attention", num_heads=None):
    """
    ç»˜åˆ¶æ³¨æ„åŠ›çƒ­åŠ›å›¾ï¼Œæ”¯æŒå•å¤´æˆ–å¤šå¤´ attention å¯è§†åŒ–

    å‚æ•°:
        src_tokens (list): æºè¯­è¨€ token åˆ—è¡¨ï¼ˆå¦‚ ['â–ein', 'â–mann', ...]ï¼‰
        tgt_tokens (list): ç›®æ ‡è¯­è¨€ token åˆ—è¡¨ï¼ˆå¦‚ ['â–a', 'â–man', ...]ï¼‰
        attention_matrix (np.ndarray or torch.Tensor): æ³¨æ„åŠ›çŸ©é˜µï¼Œå½¢çŠ¶ä¸º (num_heads, tgt_len, src_len)
        filename (str): ä¿å­˜å›¾åƒçš„æ–‡ä»¶åå‰ç¼€
        num_heads (int): è¦å¯è§†åŒ–çš„å¤´æ•°ï¼ˆé»˜è®¤å…¨éƒ¨ç»˜åˆ¶ï¼‰
    """
    if isinstance(attention_matrix, torch.Tensor):
        attention_matrix = attention_matrix.detach().cpu().numpy()
    
    # å¦‚æœæ˜¯3ç»´(num_heads, tgt_len, src_len)ï¼Œé€‰æ‹©è¦å¯è§†åŒ–çš„å¤´æ•°
    if len(attention_matrix.shape) == 3:
        total_heads = attention_matrix.shape[0]
        if num_heads is None:
            num_heads = min(4, total_heads)  # é»˜è®¤æœ€å¤šæ˜¾ç¤º4ä¸ªå¤´
        
        # åˆ›å»ºå­å›¾
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        axes = axes.flatten()
        
        for i in range(min(num_heads, 4)):
            if i < total_heads:
                ax = axes[i]
                sns.heatmap(attention_matrix[i], 
                           xticklabels=src_tokens, 
                           yticklabels=tgt_tokens,
                           cmap='Blues', 
                           ax=ax,
                           cbar_kws={'shrink': 0.8})
                ax.set_title(f'Attention Head {i+1}')
                ax.set_xlabel('Source Tokens')
                ax.set_ylabel('Target Tokens')
        
        # éšè—å¤šä½™çš„å­å›¾
        for i in range(num_heads, 4):
            axes[i].set_visible(False)
            
        plt.tight_layout()
        plt.savefig(f"{filename}_heads.png", dpi=300, bbox_inches='tight')
        plt.close()
        
    else:
        # 2ç»´çŸ©é˜µï¼Œç›´æ¥ç»˜åˆ¶
        plt.figure(figsize=(10, 8))
        sns.heatmap(attention_matrix, 
                   xticklabels=src_tokens, 
                   yticklabels=tgt_tokens,
                   cmap='Blues',
                   cbar_kws={'shrink': 0.8})
        plt.title('Attention Weights')
        plt.xlabel('Source Tokens')
        plt.ylabel('Target Tokens')
        plt.tight_layout()
        plt.savefig(f"{filename}.png", dpi=300, bbox_inches='tight')
        plt.close()

def create_attention_html_report(src_sentence, tgt_sentence, attention_weights, output_file="attention_report.html"):
    """
    ç”Ÿæˆäº¤äº’å¼ HTML æ³¨æ„åŠ›å¯è§†åŒ–æŠ¥å‘Š
    """
    # è½¬æ¢attentionæƒé‡ä¸ºåˆ—è¡¨æ ¼å¼
    if isinstance(attention_weights, torch.Tensor):
        attention_weights = attention_weights.detach().cpu().numpy()
    
    # å¦‚æœæ˜¯å¤šå¤´æ³¨æ„åŠ›ï¼Œå–å¹³å‡
    if len(attention_weights.shape) == 3:
        attention_weights = np.mean(attention_weights, axis=0)
    
    # HTMLæ¨¡æ¿
    html_template = Template('''
    <!DOCTYPE html>
    <html>
    <head>
        <title>Attention Visualization</title>
        <style>
            body { font-family: Arial, sans-serif; margin: 20px; }
            .sentence { margin: 20px 0; }
            .attention-matrix { margin: 20px 0; }
            .token { display: inline-block; margin: 2px; padding: 4px 8px; border-radius: 3px; }
            table { border-collapse: collapse; margin: 20px 0; }
            td, th { border: 1px solid #ddd; padding: 8px; text-align: center; min-width: 40px; }
            .high-attention { background-color: #ff6b6b; color: white; }
            .medium-attention { background-color: #feca57; }
            .low-attention { background-color: #f8f9fa; }
        </style>
    </head>
    <body>
        <h1>ğŸ” Attention Weights Visualization</h1>
        
        <div class="sentence">
            <h2>Source (German): {{ src_sentence }}</h2>
        </div>
        
        <div class="sentence">
            <h2>Target (English): {{ tgt_sentence }}</h2>
        </div>
        
        <div class="attention-matrix">
            <h2>Attention Matrix</h2>
            <table>
                <tr>
                    <th></th>
                    {% for src_token in src_tokens %}
                    <th>{{ src_token }}</th>
                    {% endfor %}
                </tr>
                {% for i, tgt_token in enumerate(tgt_tokens) %}
                <tr>
                    <th>{{ tgt_token }}</th>
                    {% for j, src_token in enumerate(src_tokens) %}
                    <td style="background-color: rgba(102, 126, 234, {{ attention_matrix[i][j] }})">
                        {{ "%.2f"|format(attention_matrix[i][j]) }}
                    </td>
                    {% endfor %}
                </tr>
                {% endfor %}
            </table>
        </div>
        
        <div style="margin-top: 30px; color: #666; font-size: 12px;">
            Generated at: {{ timestamp }}
        </div>
    </body>
    </html>
    ''')
    
    # å‡†å¤‡æ•°æ®
    src_tokens = tokenize_de(src_sentence)
    tgt_tokens = tokenize_en(tgt_sentence)
    
    # æ¸²æŸ“HTML
    html_content = html_template.render(
        src_sentence=src_sentence,
        tgt_sentence=tgt_sentence,
        src_tokens=src_tokens,
        tgt_tokens=tgt_tokens,
        attention_matrix=attention_weights.tolist(),
        timestamp=time.strftime('%Y-%m-%d %H:%M:%S')
    )
    
    # ä¿å­˜æ–‡ä»¶
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write(html_content)
    
    print(f"âœ… Attention report saved to {output_file}")

# å…¨å±€å˜é‡å­˜å‚¨å·²åŠ è½½çš„æ¨¡å‹å’Œè¯è¡¨
_model = None
_vocab_src = None
_vocab_tgt = None

def _load_vocabularies():
    """åŠ è½½è¯è¡¨"""
    global _vocab_src, _vocab_tgt, idx_to_token_src, idx_to_token_tgt
    if _vocab_src is None or _vocab_tgt is None:
        script_dir = os.path.dirname(os.path.abspath(__file__))
        _vocab_src = torch.load(os.path.join(script_dir, "multi30k_processed_bpe/vocab_de.pth"))
        _vocab_tgt = torch.load(os.path.join(script_dir, "multi30k_processed_bpe/vocab_en.pth"))
        
        # åˆ›å»ºåå‘æ˜ å°„
        idx_to_token_src = {idx: token for token, idx in _vocab_src.items()}
        idx_to_token_tgt = {idx: token for token, idx in _vocab_tgt.items()}

def translate_german_to_english(sentence: str, beam_size=10, max_len=120, alpha=0.7, visualize=False):
    """
    è¾“å…¥ä¸€ä¸ªå¾·æ–‡å­—ç¬¦ä¸²ï¼Œè¿”å›å¯¹åº”çš„è‹±æ–‡ç¿»è¯‘ï¼Œå¹¶å¯é€‰åœ°å¯è§†åŒ– attention æƒé‡ã€‚
    
    å‚æ•°:
        sentence (str): å¾·æ–‡å¥å­ï¼ˆå­—ç¬¦ä¸²ï¼‰
        beam_size (int): Beam Search çš„æœç´¢å®½åº¦
        max_len (int): æœ€å¤§ç”Ÿæˆé•¿åº¦
        alpha (float): é•¿åº¦æƒ©ç½šç³»æ•°ï¼ˆè¶Šå¤§è¶Šå€¾å‘äºé•¿å¥ï¼‰
        visualize (bool): æ˜¯å¦ç»˜åˆ¶ attention æƒé‡çƒ­åŠ›å›¾
    
    è¿”å›:
        str: è‹±æ–‡ç¿»è¯‘ç»“æœ
    """
    global _model, _vocab_src, _vocab_tgt
    
    # åŠ è½½è¯è¡¨ï¼ˆé¦–æ¬¡è°ƒç”¨æ—¶åŠ è½½ï¼‰
    _load_vocabularies()
    
    # åŠ è½½æ¨¡å‹ï¼ˆé¦–æ¬¡è°ƒç”¨æ—¶åŠ è½½ï¼‰
    if _model is None:
        _model = _load_model()
    
    model = _model
    vocab_src = _vocab_src
    vocab_tgt = _vocab_tgt
    device = next(model.parameters()).device
    
    # ç¡®ä¿ BPE åˆ†è¯å™¨å·²åŠ è½½
    _load_bpe_models()
    
    # ä½¿ç”¨ BPE åˆ†è¯å¹¶è½¬æ¢ä¸ºç´¢å¼•
    src_tokens = tokenize_de(sentence)
    src_indices = [BOS_IDX]
    if vocab_src is not None:
        for token in src_tokens:
            if token in vocab_src:
                src_indices.append(vocab_src[token])
            else:
                src_indices.append(0)  # UNK token
    src_indices.append(EOS_IDX)
    src_tensor = torch.tensor(src_indices, dtype=torch.long).unsqueeze(0).to(device)
    
    # æ„å»ºæ©ç 
    src_mask = torch.zeros((src_tensor.size(1), src_tensor.size(1)), dtype=torch.bool).to(device)
    src_pad_mask = (src_tensor == PAD_IDX).to(device)
    
    with torch.no_grad():
        memory = model.encoder(src_tensor, src_mask, src_pad_mask)
    
    # Beam Search åˆå§‹åŒ–
    hypotheses = [[BOS_IDX]]
    hyp_scores = torch.zeros(1, device=device)
    completed_hypotheses = []
    
    # Beam Search è§£ç 
    for step in range(max_len):
        if not hypotheses:
            break
            
        new_hypotheses = []
        new_scores = []
        
        for i, hyp in enumerate(hypotheses):
            if hyp[-1] == EOS_IDX:
                completed_hypotheses.append((hyp, hyp_scores[i].item()))
                continue
                
            # å‡†å¤‡å½“å‰å‡è®¾çš„å¼ é‡
            tgt_tensor = torch.tensor([hyp], dtype=torch.long, device=device)
            tgt_mask = generate_square_subsequent_mask(tgt_tensor.size(1)).to(device)
            tgt_pad_mask = (tgt_tensor == PAD_IDX).to(device)
            
            # æ¨¡å‹å‰å‘ä¼ æ’­
            out = model.decoder(tgt_tensor, memory, tgt_mask, tgt_pad_mask, src_pad_mask)
            log_probs = torch.log_softmax(out[0, -1, :], dim=-1)
            
            # è·å–top-kå€™é€‰
            topk_log_probs, topk_indices = log_probs.topk(beam_size, dim=-1)
            
            for k in range(beam_size):
                new_hyp = hyp + [topk_indices[k].item()]
                new_score = hyp_scores[i] + topk_log_probs[k]
                new_hypotheses.append(new_hyp)
                new_scores.append(new_score)
        
        if not new_hypotheses:
            break
            
        # æŒ‰åˆ†æ•°æ’åºå¹¶ä¿ç•™top-k
        scored_hyps = list(zip(new_hypotheses, new_scores))
        scored_hyps.sort(key=lambda x: x[1], reverse=True)
        
        hypotheses = [hyp for hyp, _ in scored_hyps[:beam_size]]
        hyp_scores = torch.tensor([score for _, score in scored_hyps[:beam_size]], device=device)
    
    # é€‰æ‹©æœ€ä½³å‡è®¾
    if completed_hypotheses:
        # åº”ç”¨é•¿åº¦æƒ©ç½š
        best_hyp, best_score = max(completed_hypotheses, 
                                 key=lambda x: x[1] / (len(x[0]) ** alpha))
    else:
        best_hyp = hypotheses[0] if hypotheses else [BOS_IDX, EOS_IDX]
    
    # ç§»é™¤ç‰¹æ®Šæ ‡è®°å¹¶è½¬æ¢ä¸ºæ–‡æœ¬
    if BOS_IDX in best_hyp:
        best_hyp = best_hyp[1:]  # ç§»é™¤BOS
    if EOS_IDX in best_hyp:
        best_hyp = best_hyp[:best_hyp.index(EOS_IDX)]  # ç§»é™¤EOSåŠå…¶åé¢çš„å†…å®¹
    
    # è½¬æ¢ç´¢å¼•ä¸ºtokens - ä½¿ç”¨å…¨å±€çš„åå‘æ˜ å°„
    tgt_tokens = []
    if idx_to_token_tgt is not None:
        for idx in best_hyp:
            if idx in idx_to_token_tgt:
                tgt_tokens.append(idx_to_token_tgt[idx])
            else:
                tgt_tokens.append('<unk>')
    
    # å°†BPE piecesåˆå¹¶ä¸ºæœ€ç»ˆæ–‡æœ¬
    _load_bpe_models()  # ç¡®ä¿sp_enå·²åŠ è½½
    if sp_en is not None:
        try:
            # ä½¿ç”¨ decode_pieces æ–¹æ³•
            translated_text = sp_en.decode_pieces(tgt_tokens)
        except Exception:
            # å¦‚æœè§£ç å¤±è´¥ï¼Œä½¿ç”¨ç®€å•çš„å­—ç¬¦ä¸²æ‹¼æ¥
            token_string = ''.join(tgt_tokens).replace('â–', ' ').strip()
            translated_text = token_string
    else:
        # å¤‡ç”¨æ–¹æ¡ˆï¼šç®€å•æ‹¼æ¥
        token_string = ''.join(tgt_tokens).replace('â–', ' ').strip()
        translated_text = token_string
    
    # å¯è§†åŒ–ï¼ˆå¦‚æœéœ€è¦ï¼‰
    if visualize:
        try:
            create_attention_html_report(sentence, translated_text, torch.zeros(1, 10, 10))
            print("âœ… Attention visualization saved")
        except Exception as e:
            print("âš ï¸ Attention visualization failed:", e)
    
    return translated_text

# å†…éƒ¨å‡½æ•°ï¼šåŠ è½½æ¨¡å‹
def _load_model():
    # å¯¼å…¥ä¸è®­ç»ƒæ—¶ç›¸åŒçš„ç»„ä»¶
    from models.Encoder import Encoder
    from models.Decoder import Decoder
    
    script_dir = os.path.dirname(os.path.abspath(__file__))
    vocab_src = torch.load(os.path.join(script_dir, "multi30k_processed_bpe/vocab_de.pth"))
    vocab_tgt = torch.load(os.path.join(script_dir, "multi30k_processed_bpe/vocab_en.pth"))
    
    # åˆ›å»ºä¸è®­ç»ƒæ—¶ç›¸åŒçš„ç¼–ç å™¨å’Œè§£ç å™¨
    encoder = Encoder(
        vocab_size=len(vocab_src),
        embed_dim=512,
        num_heads=8,
        ffn_hidden_dim=2048,
        num_layers=3,  # å®é™…ä¿å­˜çš„æ¨¡å‹æ˜¯3å±‚
        dropout=0.1,
        padding_idx=1,
        norm_first=True,  # ä¸train.pyä¸­çš„NORM_FIRST=Trueä¿æŒä¸€è‡´
        activation='relu'  # ä¸train.pyä¸­çš„ACTIVATION='relu'ä¿æŒä¸€è‡´
    )
    
    decoder = Decoder(
        vocab_size=len(vocab_tgt),
        embed_dim=512,
        num_heads=8,
        ffn_hidden_dim=2048,
        num_layers=3,  # å®é™…ä¿å­˜çš„æ¨¡å‹æ˜¯3å±‚
        dropout=0.1,
        padding_idx=1,
        norm_first=True,
        activation='relu'
    )
    
    # åˆ›å»ºä¸è®­ç»ƒæ—¶ç›¸åŒçš„Seq2SeqTransformer
    class Seq2SeqTransformer(nn.Module):
        def __init__(self, encoder, decoder):
            super().__init__()
            self.encoder = encoder
            self.decoder = decoder
        
        def forward(self, src, tgt, src_mask, tgt_mask, src_key_padding_mask, tgt_key_padding_mask):
            memory = self.encoder(src, src_mask, src_key_padding_mask)
            output = self.decoder(tgt, memory, tgt_mask, tgt_key_padding_mask, src_key_padding_mask)
            return output
    
    model = Seq2SeqTransformer(encoder, decoder)
    
    model_path = os.path.join(script_dir, "transformer_model.pth")
    model.load_state_dict(torch.load(model_path, map_location='cpu'))
    model.eval()
    return model

# æ¨¡å‹è¶…å‚æ•°ï¼ˆéœ€ä¸è®­ç»ƒæ—¶ä¿æŒä¸€è‡´ï¼‰
EMB_SIZE = 512
FFN_HID_DIM = 2048
NUM_ENCODER_LAYERS = 6
NUM_DECODER_LAYERS = 6
NUM_HEADS = 8
DROPOUT = 0.1
PAD_IDX = 1
BOS_IDX = 2
EOS_IDX = 3
